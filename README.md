===========================================
Assignment 2: Object Recognition on CIFAR-10
===========================================

Author:  Ayan Asif  
Roll No: 22I-1097  
Course: Deep Learning for Perception (DLP)  
Institution: NUCES FAST Islamabad  
Date: October 2025

-------------------------------------------
1. PROJECT OVERVIEW
-------------------------------------------
This project explores the performance of three neural network architectures — 
a Fully-Connected Artificial Neural Network (ANN), a Convolutional Neural Network (CNN), 
and a Hybrid CNN+ANN — on the CIFAR-10 dataset.

The objective was to design, train, and analyze models **without pretrained weights, 
transfer learning, or standard architectures** (e.g., ResNet, VGG). 
Experiments focus on architectural design, activation functions, normalization, 
regularization, and optimization settings.

-------------------------------------------
2. FILES AND STRUCTURE
-------------------------------------------

├── ANN.ipynb             # Implements and trains the fully connected ANN
├── CNN.ipynb             # Implements and trains the handcrafted CNN
├── Hybrid.ipynb          # Combines CNN feature extraction with ANN classifier
├── i221097_A_A2_Report.pdf  # Research-style report (LaTeX compiled)
├── README.txt            # This file
└── /data                 # Folder automatically created by torchvision (CIFAR-10)

-------------------------------------------
3. REQUIREMENTS
-------------------------------------------

Framework: PyTorch >= 2.0  
Python >= 3.9  
Dependencies:
    torch
    torchvision
    numpy
    matplotlib
    tqdm (optional for progress bars)

-------------------------------------------
4. HOW TO RUN
-------------------------------------------

1. Open each notebook (ANN.ipynb, CNN.ipynb, Hybrid.ipynb).
2. Run all cells sequentially from top to bottom.
3. The dataset will automatically download to the ./data folder.
4. Each notebook prints per-epoch training accuracy and final test accuracy.

Approximate runtimes (CPU):
- ANN: ~5–7 minutes for 10 epochs
- CNN: ~10–15 minutes for 5 epochs
- Hybrid: ~15–20 minutes for 5 epochs

If a CUDA GPU is available, set:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

-------------------------------------------
5. RESULTS SUMMARY
-------------------------------------------

| Model              | Train Acc | Test Acc | Remarks |
|---------------------|------------|-----------|----------|
| ANN (ReLU)          | 60.5%      | 56.9%     | Baseline MLP |
| ANN + Weight Decay  | 61.0%      | 59.0%     | Improved generalization |
| CNN (Baseline)      | 75.2%      | 75.2%     | Strong spatial feature learning |
| CNN + BatchNorm     | 73.5%      | 74.7%     | Smoother convergence |
| CNN + Cosine LR     | 77.3%      | 75.4%     | Best CNN stability |
| Hybrid CNN+ANN      | 68.2%      | 71.4%     | Balanced trade-off |

-------------------------------------------
6. REPRODUCIBILITY
-------------------------------------------

Random seeds were fixed for Python, NumPy, and PyTorch to ensure reproducibility:
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)

Training loops produce deterministic results given identical environments.

-------------------------------------------
7. LESSONS AND INSIGHTS
-------------------------------------------

- ANN underperforms due to lack of spatial inductive bias.
- CNN achieves strong performance through local feature extraction.
- Hybrid model shows trade-offs between flexibility and computational cost.
- BatchNorm, Dropout, and LR scheduling significantly enhance convergence.
- CosineAnnealingLR provides smoother and more robust training than StepLR.

-------------------------------------------
8. REFERENCES
-------------------------------------------

1. Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images.
2. Goodfellow, I., Bengio, Y., Courville, A. (2016). Deep Learning. MIT Press.
3. PyTorch Official Documentation: https://pytorch.org/docs/stable/

README generated by ChatGPT.

-------------------------------------------
END OF README
-------------------------------------------
